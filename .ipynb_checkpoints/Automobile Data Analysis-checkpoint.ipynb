{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automobile Data: Car Price Prediction\n",
    "\n",
    "In this project I will explore features of automobile data set to predict price of car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling is the process of converting data from the initial format to a clean format that may be better for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas, numpy, seaborn, matplotlib, scipy library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!head -n5 datasets/autodata.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the online file by the URL provides above, and assign it to variable \"df\"\n",
    "other_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv\"\n",
    "df = pd.read_csv(other_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 rows using dataframe.head() method\n",
    "print(\"The first 5 rows of the dataframe\") \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Headers\n",
    "<p>\n",
    "To better describe the data, let's introduce headers for the dataframe, this information is available at:  <a href=\"https://archive.ics.uci.edu/ml/datasets/Automobile\" target=\"_blank\">https://archive.ics.uci.edu/ml/datasets/Automobile</a>\n",
    "</p>\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create headers list\n",
    "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\n",
    "print(\"headers\\n\", headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace headers and recheck the data frame\n",
    "df.columns = headers\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the \"?\" symbol with NaN\n",
    "df.replace('?', np.NaN , inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating for Missing Data\n",
    "missing_data = df.isnull()\n",
    "missing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in each column\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace data by mean\n",
    "1. \"normalized-losses\": 41 missing data, replace them with mean\n",
    "2. \"stroke\": 4 missing data, replace them with mean\n",
    "3. \"bore\": 4 missing data, replace them with mean\n",
    "4. \"horsepower\": 2 missing data, replace them with mean\n",
    "5. \"peak-rpm\": 2 missing data, replace them with mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the column \"normalized-losses\"\n",
    "avg_norm_loss = df[\"normalized-losses\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of normalized-losses:\", avg_norm_loss)\n",
    "# replace NaN by mean value in \"normalized-losses\" column\n",
    "df[\"normalized-losses\"].replace(np.nan, avg_norm_loss, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the column \"bore\"\n",
    "avg_bore=df['bore'].astype('float').mean(axis=0)\n",
    "print(\"Average of bore:\", avg_bore)\n",
    "# replace NaN by mean value in \"bore\" column\n",
    "df[\"bore\"].replace(np.nan, avg_bore, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the mean vaule for \"stroke\" column\n",
    "avg_stroke = df[\"stroke\"].astype(\"float\").mean(axis = 0)\n",
    "print(\"Average of stroke:\", avg_stroke)\n",
    "# replace NaN by mean value in \"stroke\" column\n",
    "df[\"stroke\"].replace(np.nan, avg_stroke, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the mean vaule for \"horsepower\" column\n",
    "avg_horsepower = df['horsepower'].astype('float').mean(axis=0)\n",
    "print(\"Average horsepower:\", avg_horsepower)\n",
    "# replace NaN by mean value in \"horsepower\" column\n",
    "df['horsepower'].replace(np.nan, avg_horsepower, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the mean vaule for \"peak-rpm\" column\n",
    "avg_peakrpm = df['peak-rpm'].astype('float').mean(axis=0)\n",
    "print(\"Average peak rpm:\", avg_peakrpm)\n",
    "# replace NaN by mean value in \"peak-rpm\" column\n",
    "df['peak-rpm'].replace(np.nan, avg_peakrpm, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace \"num-of-doors\" by frequency: 2 missing data, replace them with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the cell value\n",
    "df['num-of-doors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the most frequent value\n",
    "df['num-of-doors'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing 'num-of-doors' values by the most frequent \n",
    "df[\"num-of-doors\"].replace(np.nan, \"four\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the whole row: \"price\": 4 missing data (Any data entry without price data cannot be used for prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values along the column \"price\" \n",
    "df.dropna(subset=[\"price\"], axis=0, inplace=True)\n",
    "\n",
    "# reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types of the data frame\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types to proper format\n",
    "df[[\"bore\", \"stroke\"]] = df[[\"bore\", \"stroke\"]].astype(\"float\")\n",
    "df[[\"normalized-losses\"]] = df[[\"normalized-losses\"]].astype(\"int\")\n",
    "df[[\"price\"]] = df[[\"price\"]].astype(\"float\")\n",
    "df[[\"peak-rpm\"]] = df[[\"peak-rpm\"]].astype(\"float\")\n",
    "\n",
    "#List data type after conversion\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mpg to L/100km by mathematical operation (235 divided by mpg)\n",
    "df['city-L/100km'] = 235/df[\"city-mpg\"]\n",
    "\n",
    "# transform mpg to L/100km by mathematical operation (235 divided by mpg)\n",
    "df[\"highway-L/100km\"] = 235/df[\"highway-mpg\"]\n",
    "\n",
    "# rename column name from \"highway-mpg\" to \"highway-L/100km\"\n",
    "# df.rename(columns={\"highway-mpg\":'highway-L/100km'}, inplace=True)\n",
    "\n",
    "# check your transformed data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization is the process of transforming values of several variables into a similar range. Typical normalizations include scaling the variable so the variable average is 0, scaling the variable so the variance is 1, or scaling variable so the variable values range from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace (original value) by (original value)/(maximum value)\n",
    "df['length'] = df['length']/df['length'].max()\n",
    "df['width'] = df['width']/df['width'].max()\n",
    "df['height'] = df['height']/df['height'].max() \n",
    "\n",
    "# show the scaled columns\n",
    "df[[\"length\",\"width\",\"height\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning is a process of transforming continuous numerical variables into discrete categorical 'bins', for grouped analysis. \n",
    "\n",
    "In this dataset, \"horsepower\" is a real valued variable ranging from 48 to 288, it has 57 unique values. I will use the Pandas method 'cut' to segment the 'horsepower' column into 3 bins: high horsepower, medium horsepower, and little horsepower (3 types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data type conversion\n",
    "df[\"horsepower\"]=df[\"horsepower\"].astype(int, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of horspower, to see what the distribution of horsepower looks like\n",
    "%matplotlib inline\n",
    "plt.hist(df[\"horsepower\"])\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.xlabel(\"Horsepower\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Horsepower Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new bins\n",
    "bins = np.linspace(min(df[\"horsepower\"]), max(df[\"horsepower\"]), 4)\n",
    "group_names = ['Low', 'Medium', 'High']\n",
    "df['horsepower-binned'] = pd.cut(df['horsepower'], bins, labels = group_names, include_lowest = True )\n",
    "df[\"horsepower-binned\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.bar(group_names, df[\"horsepower-binned\"].value_counts())\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.xlabel(\"Horsepower\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Horsepower bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw historgram of attribute \"horsepower\" with bins = 3\n",
    "plt.hist(df[\"horsepower\"], bins = 3)\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.xlabel(\"Horsepower\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Horsepower Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An indicator variable (or dummy variable) is a numerical variable used to label categories. They are called 'dummies' because the numbers themselves don't have inherent meaning. These variables can be used for regression analysis. To use fuel type attribute in regression analysis, I convert \"fuel-type\" into indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variable_1 = pd.get_dummies(df[\"fuel-type\"])\n",
    "dummy_variable_1.rename(columns={'gas':'fuel-type-gas', 'diesel':'fuel-type-diesel'}, inplace=True)\n",
    "dummy_variable_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data frame \"df\" and \"dummy_variable_1\" \n",
    "df = pd.concat([df, dummy_variable_1], axis = 1)\n",
    "\n",
    "# drop original column \"fuel-type\" from \"df\"\n",
    "df.drop(\"fuel-type\", axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indicator variables of aspiration and assign it to data frame \"dummy_variable_2\"\n",
    "dummy_variable_2 = pd.get_dummies(df['aspiration'])\n",
    "\n",
    "# change column names for clarity\n",
    "dummy_variable_2.rename(columns={'std':'aspiration-std', 'turbo': 'aspiration-turbo'}, inplace=True)\n",
    "\n",
    "# show first 5 instances of data frame \"dummy_variable_1\"\n",
    "dummy_variable_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the new dataframe to the original datafram\n",
    "df = pd.concat([df, dummy_variable_2], axis=1)\n",
    "\n",
    "# drop original column \"aspiration\" from \"df\"\n",
    "df.drop('aspiration', axis = 1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the clean dataset to csv\n",
    "df.to_csv(\"automobile_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis involves examining the distribution of various variables in the dataset, identifying outliers, finding trends and patterns, looking for relationships between variables by using heat maps or correlation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous numerical variables are variables that may contain any value within some range. Continuous numerical variables can have the type \"int64\" or \"float64\". A great way to visualize these variables is by using scatterplots with fitted lines.\n",
    "\n",
    "In order to start understanding the relationship between an individual variable and the price, I have used \"regplot\", which plots the scatterplot plus the fitted regression line for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engine Size Vs Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engine size as potential predictor variable of price\n",
    "sns.regplot(x=\"engine-size\", y=\"price\", data=df)\n",
    "plt.ylim(0,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the engine-size goes up, the price goes up: this indicates a positive direct correlation between these two variables. Engine size seems like a pretty good predictor of price since the regression line is almost a perfect diagonal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"engine-size\", \"price\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I examined the correlation between 'engine-size' and 'price' and saw it's approximately 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highway mpg Vs Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"highway-mpg\", y=\"price\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the highway-mpg goes up, the price goes down: this indicates an inverse/negative relationship between these two variables. Highway mpg could potentially be a predictor of price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['highway-mpg', 'price']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I examined the correlation between 'highway-mpg' and 'price' and saw it's approximately -0.704. Now Let's check if \"Peak-rpm\" as a predictor variable of \"price\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peak RPM  Vs Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"peak-rpm\", y=\"price\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak rpm does not seem like a good predictor of the price at all since the regression line is close to horizontal. Also, the data points are very scattered and far from the fitted line, showing lots of variability. Therefore it is not a reliable variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['peak-rpm','price']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between 'peak-rpm' and 'price'is approximately -0.101616 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stroke Vs Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"stroke\",\"price\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the correlation between \"stroke\" and \"price\" is approximately 0.082"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a weak correlation between the variable 'stroke' and 'price.' and such regression will not work well. This can be demonstrated using regplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"stroke\", y=\"price\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are variables that describe a 'characteristic' of a data unit, and are selected from a small group of categories. The categorical variables can have the type \"object\" or \"int64\". A good way to visualize categorical variables is by using boxplots. Let's look at the relationship between \"body-style\" and \"price\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Body-Style Vs Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"body-style\", y=\"price\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the distributions of price between the different body-style categories have a significant overlap, and so body-style would not be a good predictor of price. Let's examine engine \"engine-location\" and \"price\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engine Location Vs Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"engine-location\", y=\"price\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it can be seen that the distribution of price between these two engine-location categories, front and rear, are distinct enough to take engine-location as a potential good predictor of price.Now, let's examine \"drive-wheels\" and \"price\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drive Wheels  Vs Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive-wheels\n",
    "sns.boxplot(x=\"drive-wheels\", y=\"price\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the distribution of price between the different drive-wheels categories differs; so drive-wheels could potentially be a predictor of price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe all the columns in \"df\" statistical summary \n",
    "df.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value-counts is a good way of understanding how many units of each characteristic/variable we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive-wheels as variable\n",
    "drive_wheels_counts = df['drive-wheels'].value_counts().to_frame()\n",
    "drive_wheels_counts.rename(columns={'drive-wheels': 'value_counts'}, inplace=True)\n",
    "drive_wheels_counts.index.name = 'drive-wheels'\n",
    "print(drive_wheels_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine-location as variable\n",
    "engine_loc_counts = df['engine-location'].value_counts().to_frame()\n",
    "engine_loc_counts.rename(columns={'engine-location': 'value_counts'}, inplace=True)\n",
    "engine_loc_counts.index.name = 'engine-location'\n",
    "print(engine_loc_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On examining the value counts of the engine location, it can be concluded that it would not be a good predictor variable for the price. This is because there are three cars with a rear engine and 198 with an engine in the front, this result is skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"groupby\" method groups data by different categories. The data is grouped based on one or several variables and analysis is performed on the individual groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_one = df[['drive-wheels','body-style','price']]\n",
    "df_group_one = df_group_one.groupby(['drive-wheels'],as_index=False).mean()\n",
    "df_group_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above data, it seems rear-wheel drive vehicles are, on average, the most expensive, while 4-wheel and front-wheel are approximately the same in price.\n",
    "\n",
    "Now, let's group by both 'drive-wheels' and 'body-style'. This groups the dataframe by the unique combinations 'drive-wheels' and 'body-style'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping results\n",
    "df_gptest = df[['drive-wheels','body-style','price']]\n",
    "grouped_test1 = df_gptest.groupby(['drive-wheels','body-style'],as_index=False).mean().sort_values('price')\n",
    "grouped_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This grouped data is much easier to visualize when it is made into a pivot table. A pivot table is like an Excel spreadsheet, with one variable along the column and another along the row.\n",
    "\n",
    "In this case, we will leave the drive-wheel variable as the rows of the table, and pivot body-style to become the columns of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pivot = grouped_test1.pivot(index='drive-wheels',columns='body-style')\n",
    "grouped_pivot = grouped_pivot.fillna(0) #fill missing values with 0\n",
    "grouped_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the grouped results\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolor(grouped_pivot, cmap='RdBu')\n",
    "\n",
    "#label names\n",
    "row_labels = grouped_pivot.columns.levels[1]\n",
    "col_labels = grouped_pivot.index\n",
    "\n",
    "#move ticks and labels to the center\n",
    "ax.set_xticks(np.arange(grouped_pivot.shape[1]) + 0.5, minor=False)\n",
    "ax.set_yticks(np.arange(grouped_pivot.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "#insert labels\n",
    "ax.set_xticklabels(row_labels, minor=False)\n",
    "ax.set_yticklabels(col_labels, minor=False)\n",
    "\n",
    "#rotate label if too long\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "Here we do correlation analysis amongst all the independent continuous variables and eliminate variables that have very close correlation. We also do a feature importance test to find out the importance of each independent feature as it pertains to the dependent variable. We eliminate the features that are not so important.\n",
    "\n",
    "In order to check for multicollinearity, first I am storing the names of all continuous variables in cont and categorical variables in categ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting up column names into cont and categ\n",
    "\n",
    "# df.columns\n",
    "categ = ['make', 'body-style', 'drive-wheels','engine-location', 'engine-type', 'fuel-type-diesel', 'fuel-type-gas', 'aspiration-std','aspiration-turbo','horsepower-binned']\n",
    "cont = ['symboling', 'normalized-losses', 'num-of-doors', 'wheel-base', 'length', 'width','height', 'curb-weight','num-of-cylinders','engine-size', 'fuel-system', 'bore', 'stroke', 'compression-ratio','horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
    "\n",
    "#subsetting out day into datasets having continuous and categorical variables\n",
    "df_cont = df.loc[:, cont]\n",
    "df_categ= df.loc[:, categ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Calculate the correlation between variables \n",
    "\n",
    "# setting width and height of plot\n",
    "f, ax = plt.subplots(figsize = (14, 14))\n",
    "\n",
    "#generate the correlation matrix\n",
    "corr = df_cont.corr()\n",
    "\n",
    "#putting corr into perspective via heatmap\n",
    "sns.heatmap(corr, \n",
    "            mask = np.zeros_like(corr, dtype = np.bool), \n",
    "            cmap = sns.diverging_palette(220, 10, as_cmap = True), \n",
    "            square = True, \n",
    "            ax = ax, \n",
    "            annot = True, \n",
    "            cbar = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation plot, we can see that features that affect price could be: highway-mpg, city-mpg, horsepower, engine-size, curb-weight, width, length, wheel-base and bore. The parameters from wheel-base, length, width, height, curb-weight, engine-size and bore have dependence on each other. So, we may choose only some of these features. Either engine-size or curb-weight can be selected because they have strong correlation. We may choose highway-mpg or city-mpg beacuse of high correlation. Let's investigate further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Coefficient and P-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'wheel-base' Vs 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df['wheel-base'], df['price'])\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is  <  0.001, the correlation between wheel-base and price is statistically significant, although the linear relationship isn't extremely strong (~0.585). So this variable may be eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  'horsepower' Vs 'price'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df['horsepower'], df['price'])\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P = \", p_value)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is  <  0.001, the correlation between horsepower and price is statistically significant, and the linear relationship is quite strong (~0.809, close to 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'length' Vs 'price'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df['length'], df['price'])\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P = \", p_value)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is  <  0.001, the correlation between length and price is statistically significant, and the linear relationship is moderately strong (~0.691)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  'width' Vs 'price':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df['width'], df['price'])\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is < 0.001, the correlation between width and price is statistically significant, and the linear relationship is quite strong (~0.751)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'curb-weight' Vs 'price':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df['curb-weight'], df['price'])\n",
    "print( \"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P = \", p_value)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is  <  0.001, the correlation between curb-weight and price is statistically significant, and the linear relationship is quite strong (~0.834)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  'engine-size' Vs 'price':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df['engine-size'], df['price'])\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is  <  0.001, the correlation between engine-size and price is statistically significant, and the linear relationship is very strong (~0.872)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'bore' Vs 'price':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df['bore'], df['price'])\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =  \", p_value ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is  <  0.001, the correlation between bore and price is statistically significant, but the linear relationship is only moderate (~0.521)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### City-mpg Vs Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df['city-mpg'], df['price'])\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P = \", p_value)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is  <  0.001, the correlation between city-mpg and price is statistically significant, and the coefficient of ~ -0.687 shows that the relationship is negative and moderately strong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highway-mpg Vs Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df['highway-mpg'], df['price'])\n",
    "print( \"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P = \", p_value ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is < 0.001, the correlation between highway-mpg and price is statistically significant, and the coefficient of ~ -0.705 shows that the relationship is negative and moderately strong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA: Analysis of Variance\n",
    "\n",
    "The Analysis of Variance (ANOVA) is a statistical method used to test whether there are significant differences between the means of two or more groups. ANOVA returns two parameters:\n",
    "\n",
    "F-test score: ANOVA assumes the means of all groups are the same, calculates how much the actual means deviate from the assumption, and reports it as the F-test score. A larger score means there is a larger difference between the means.\n",
    "\n",
    "P-value: P-value tells how statistically significant is our calculated score value.\n",
    "\n",
    "If the price variable is strongly correlated with the variable, expect ANOVA to return a sizeable F-test score and a small p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_test2=df_gptest[['drive-wheels', 'price']].groupby(['drive-wheels'])\n",
    "grouped_test2.get_group('4wd')['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA\n",
    "f_val, p_val = stats.f_oneway(grouped_test2.get_group('fwd')['price'], grouped_test2.get_group('rwd')['price'], grouped_test2.get_group('4wd')['price'])  \n",
    " \n",
    "print( \"ANOVA results: F=\", f_val, \", P =\", p_val)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_val, p_val = stats.f_oneway(grouped_test2.get_group('fwd')['price'], grouped_test2.get_group('rwd')['price'])  \n",
    " \n",
    "print( \"ANOVA results: F=\", f_val, \", P =\", p_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_val, p_val = stats.f_oneway(grouped_test2.get_group('4wd')['price'], grouped_test2.get_group('rwd')['price'])  \n",
    "   \n",
    "print( \"ANOVA results: F=\", f_val, \", P =\", p_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_val, p_val = stats.f_oneway(grouped_test2.get_group('4wd')['price'], grouped_test2.get_group('fwd')['price'])  \n",
    " \n",
    "print(\"ANOVA results: F=\", f_val, \", P =\", p_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Important Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now have a better idea of what the data looks like and which variables are important to take into account when predicting the car price. I have narrowed it down to the following variables:\n",
    "\n",
    "Continuous numerical variables:\n",
    "\n",
    "1. Length\n",
    "2. Width\n",
    "3. Curb-weight\n",
    "4. Engine-size\n",
    "5. Horsepower\n",
    "6. City-mpg\n",
    "7. Highway-mpg\n",
    "8. Wheel-base\n",
    "9. Bore\n",
    "\n",
    "Categorical variables: Drive-wheels\n",
    "\n",
    "Now I can build machine learning models to automate the analysis, feeding the model with variables that meaningfully affect the target variable will improve the model's prediction performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the preprocessing has been done, let us split the data into train and test. The model will be made on the train data, and then implemented on the test data. Then the accuracy of the model will be determined based on the accuracy obtained on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "y_data = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "x_data=df.drop('price',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.10, random_state=1)\n",
    "\n",
    "#\n",
    "print(\"Number of test samples :\", x_test.shape[0])\n",
    "print(\"Number of training samples:\",x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will develop several models that will predict the price of the car using the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression object\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to look at how highway-mpg can help predict car price. Using simple linear regression, I will create a linear function with \"highway-mpg\" as the predictor variable and the \"price\" as the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear model using highway-mpg\n",
    "X = x_train[['highway-mpg']]\n",
    "Y = y_train\n",
    "lm.fit(X,Y)\n",
    "# Find the R^2\n",
    "print('The R-square of training data is: ', lm.score(X, Y))\n",
    "print('The R-square of test data is: ', lm.score(x_test[['horsepower']], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcross = cross_val_score(lm, x_data[['horsepower']], y_data, cv=4)\n",
    "print(\"The mean of the folds are\", Rcross.mean(), \"and the standard deviation is\" , Rcross.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output a prediction\n",
    "Yhat=lm.predict(X)\n",
    "print('The output of the first four predicted value is: ', Yhat[0:4])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(df['price'], Yhat)\n",
    "print('The mean square error of price and predicted value is: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will train the model using 'engine-size' as the independent variable and 'price' as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression object\n",
    "lm1 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear model using highway-mpg\n",
    "lm1.fit(df[['engine-size']], df[['price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the slope and intercept of the model\n",
    "print(lm1.intercept_)\n",
    "print(lm1.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Linear Regression is very similar to Simple Linear Regression, but this method is used to explain the relationship between one continuous response (dependent) variable and two or more predictor (independent) variables.\n",
    "\n",
    "From the previous section I know that other good predictors of price could be: Horsepower, Curb-weight, Engine-size and Highway-mpg. Let's develop a model using these variables as the predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = df[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']]\n",
    "# fit the model \n",
    "lm.fit(Z, df['price'])\n",
    "# Find the R^2\n",
    "print('The R-square is: ', lm.score(Z, df['price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict_multifit = lm.predict(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The mean square error of price and predicted value using multifit is: ', \\\n",
    "      mean_squared_error(df['price'], Y_predict_multifit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.intercept_\n",
    "lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to simple linear regression, an excellent way to visualize the fit of the model is by using regression plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 6\n",
    "height = 5\n",
    "plt.figure(figsize=(width, height))\n",
    "sns.regplot(x=\"highway-mpg\", y=\"price\", data=df)\n",
    "plt.ylim(0,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A residual plot is a graph that shows the residuals on the vertical y-axis and the independent variable on the horizontal x-axis. If the points in a residual plot are randomly spread out around the x-axis, then a linear model is appropriate for the data. Why is that? Randomly spread out residuals means that the variance is constant, and thus the linear model is a good fit for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 6\n",
    "height = 5\n",
    "plt.figure(figsize=(width, height))\n",
    "sns.residplot(x='highway-mpg', y='price',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Linear Regression models can't be visualized with regression or residual plot. One way to look at the fit of the model is by looking at the distribution plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = lm.predict(Z)\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "ax1 = sns.distplot(df['price'], hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(Y_hat, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "\n",
    "plt.title('Actual vs Fitted Values for Price')\n",
    "plt.xlabel('Price (in dollars)')\n",
    "plt.ylabel('Proportion of Cars')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression and Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial regression is a particular case of the general linear regression model or multiple linear regression models. We get non-linear relationships by squaring or setting higher-order terms of the predictor variables. The linear model did not provide the best fit while using highway-mpg as the predictor variable. Let's see if fitting a polynomial model to the data instead helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotPolly(model, independent_variable, dependent_variabble, Name):\n",
    "    x_new = np.linspace(15, 55, 100)\n",
    "    y_new = model(x_new)\n",
    "\n",
    "    plt.plot(independent_variable, dependent_variabble, '.', x_new, y_new, '-')\n",
    "    plt.title('Polynomial Fit with Matplotlib for Price ~ Length')\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor((0.898, 0.898, 0.898))\n",
    "    fig = plt.gcf()\n",
    "    plt.xlabel(Name)\n",
    "    plt.ylabel('Price of Cars')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['highway-mpg']\n",
    "y = df['price']\n",
    "# Here we use a polynomial of the 3rd order (cubic) \n",
    "f = np.polyfit(x, y, 3)\n",
    "p = np.poly1d(f)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_squared = r2_score(y, p(x))\n",
    "print('The R-square value is: ', r_squared)\n",
    "mean_squared_error(df['price'], p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotPolly(p, x, y, 'highway-mpg')\n",
    "np.polyfit(x, y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a polynomial transform on multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=PolynomialFeatures(degree=2)\n",
    "Z_pr=pr.fit_transform(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pipelines simplify the steps of processing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input=[('scale',StandardScaler()), ('polynomial', PolynomialFeatures(include_bias=False)), ('model',LinearRegression())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline(Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(Z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypipe=pipe.predict(Z)\n",
    "ypipe[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
